# ğŸš¨ ESTRATEGIA CRÃTICA DE DATOS - InvernaderosAPI

**Fecha:** 2025-12-05
**Autor:** AnÃ¡lisis profundo del sistema
**Status:** ACCIÃ“N INMEDIATA REQUERIDA

---

## ğŸ“Š DIAGNÃ“STICO DEL PROBLEMA

### Problema Principal Identificado

**Â¡EL SISTEMA ESTÃ GUARDANDO ~5x MÃS DATOS DE LO NECESARIO!**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DÃ­a         â”‚ Lecturas        â”‚ Mensajes/minuto   â”‚ Segundos entre msgs  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Nov 29-Dec1 â”‚ ~864,000        â”‚ ~24               â”‚ ~2.5 seg             â”‚
â”‚ Dec 3-4     â”‚ ~4,300,000      â”‚ ~130              â”‚ ~0.4 seg âš ï¸ 5x MÃS â”‚
â”‚ Dec 5       â”‚ ~2,400,000*     â”‚ ~75               â”‚ ~0.8 seg âš ï¸ 3x MÃS â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
* Parcial (dÃ­a en curso)
```

### Causas RaÃ­z Identificadas

#### 1. âš ï¸ MÃšLTIPLES RÃ‰PLICAS CON SIMULACIÃ“N ACTIVADA

```bash
# PRODUCCIÃ“N tiene 2 rÃ©plicas ejecutando la simulaciÃ³n SIMULTÃNEAMENTE
kubectl get pods -n apptolast-invernadero-api-prod
  invernaderos-api-c5b6df5d8-hhj25   1/1  Running  # SIMULACIÃ“N ACTIVA
  invernaderos-api-c5b6df5d8-xw4fm   1/1  Running  # SIMULACIÃ“N ACTIVA â† DUPLICADO

# DESARROLLO tambiÃ©n tiene la simulaciÃ³n activa
kubectl get pods -n apptolast-invernadero-api-dev
  invernaderos-api-7757d88788-4qzzv  1/1  Running  # SIMULACIÃ“N ACTIVA â† TRIPLICADO
```

**Resultado:** 3 instancias generando datos cada 5 segundos = ~2.5 mensajes/segundo en lugar de 1 cada 5 segundos.

#### 2. âš ï¸ ARQUITECTURA DE ALMACENAMIENTO INEFICIENTE

Cada mensaje MQTT contiene 22 campos de sensores. Actualmente:
- **1 mensaje MQTT = 25 filas en la base de datos** (una fila por sensor + 3 metadatos)
- **~114,655 mensajes/dÃ­a** con 22 sensores = **~2.5 millones de filas/dÃ­a**

#### 3. ğŸ“ CÃLCULO DEL PROBLEMA

```
Frecuencia actual:      ~75 msgs/minuto (deberÃ­a ser ~12 msgs/minuto)
Lecturas por mensaje:   22 sensores + 3 metadatos = 25 filas
Filas por dÃ­a actual:   75 Ã— 60 Ã— 24 Ã— 22 = ~2.4M filas/dÃ­a
Filas por dÃ­a normal:   12 Ã— 60 Ã— 24 Ã— 22 = ~380K filas/dÃ­a

EXCESO: ~6x mÃ¡s datos de lo necesario
```

---

## ğŸ¯ ESTRATEGIA DE SOLUCIÃ“N MULTINIVEL

### NIVEL 1: SOLUCIÃ“N INMEDIATA (HOY)

#### A. Desactivar SimulaciÃ³n en RÃ©plicas Extra

```bash
# OPCIÃ“N 1: Reducir rÃ©plicas en producciÃ³n a 1 (recomendado si solo hay simulaciÃ³n)
kubectl scale deployment/invernaderos-api -n apptolast-invernadero-api-prod --replicas=1

# OPCIÃ“N 2: Desactivar simulaciÃ³n en producciÃ³n (mejor opciÃ³n si hay datos reales)
kubectl set env deployment/invernaderos-api -n apptolast-invernadero-api-prod \
  GREENHOUSE_SIMULATION_ENABLED=false

# Desactivar simulaciÃ³n en desarrollo tambiÃ©n
kubectl set env deployment/invernaderos-api -n apptolast-invernadero-api-dev \
  GREENHOUSE_SIMULATION_ENABLED=false
```

#### B. Aumentar Intervalo de SimulaciÃ³n

Si necesitas mantener la simulaciÃ³n, aumentar el intervalo:

```yaml
# En configmap o deployment
greenhouse:
  simulation:
    enabled: true
    interval-ms: 60000  # 1 minuto en lugar de 5 segundos
```

---

### NIVEL 2: OPTIMIZACIÃ“N DE ARQUITECTURA (ESTA SEMANA)

#### A. Cambiar Modelo de Datos: De Filas a Columnas

**ACTUAL (ineficiente):**
```sql
-- 22 filas por cada mensaje (una por sensor)
| time                | sensor_id                   | value |
|---------------------|-----------------------------| ------|
| 2025-12-05 12:00:00 | TEMPERATURA INVERNADERO 01  | 25.3  |
| 2025-12-05 12:00:00 | HUMEDAD INVERNADERO 01      | 60.2  |
| 2025-12-05 12:00:00 | TEMPERATURA INVERNADERO 02  | 24.1  |
... (22 filas por timestamp)
```

**PROPUESTO (eficiente):**
```sql
-- 1 fila por mensaje con todos los sensores
| time                | temp_01 | hum_01 | temp_02 | hum_02 | ... |
|---------------------|---------|--------|---------|--------|-----|
| 2025-12-05 12:00:00 | 25.3    | 60.2   | 24.1    | 58.5   | ... |
```

**ReducciÃ³n:** De 25 filas a 1 fila por mensaje = **96% menos filas**

#### B. Implementar Tabla Denormalizada

```sql
-- Nueva tabla optimizada para datos de invernadero
CREATE TABLE iot.greenhouse_readings (
    time TIMESTAMPTZ NOT NULL,
    greenhouse_id UUID NOT NULL,
    tenant_id UUID NOT NULL,
    
    -- Temperaturas
    temp_invernadero_01 DOUBLE PRECISION,
    temp_invernadero_02 DOUBLE PRECISION,
    temp_invernadero_03 DOUBLE PRECISION,
    
    -- Humedades
    hum_invernadero_01 DOUBLE PRECISION,
    hum_invernadero_02 DOUBLE PRECISION,
    hum_invernadero_03 DOUBLE PRECISION,
    
    -- Sectores (12 campos)
    sector_01_01 DOUBLE PRECISION,
    sector_01_02 DOUBLE PRECISION,
    sector_01_03 DOUBLE PRECISION,
    sector_01_04 DOUBLE PRECISION,
    sector_02_01 DOUBLE PRECISION,
    sector_02_02 DOUBLE PRECISION,
    sector_02_03 DOUBLE PRECISION,
    sector_02_04 DOUBLE PRECISION,
    sector_03_01 DOUBLE PRECISION,
    sector_03_02 DOUBLE PRECISION,
    sector_03_03 DOUBLE PRECISION,
    sector_03_04 DOUBLE PRECISION,
    
    -- Extractores
    extractor_01 DOUBLE PRECISION,
    extractor_02 DOUBLE PRECISION,
    extractor_03 DOUBLE PRECISION,
    
    -- Reserva
    reserva DOUBLE PRECISION,
    
    PRIMARY KEY (time, greenhouse_id)
);

-- Convertir a hypertable
SELECT create_hypertable('iot.greenhouse_readings', 'time', 
    chunk_time_interval => INTERVAL '1 day',
    if_not_exists => TRUE
);

-- Configurar compresiÃ³n agresiva
ALTER TABLE iot.greenhouse_readings SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'greenhouse_id, tenant_id',
    timescaledb.compress_orderby = 'time DESC'
);

-- Comprimir despuÃ©s de 6 horas (mÃ¡s agresivo)
SELECT add_compression_policy('iot.greenhouse_readings', 
    compress_after => INTERVAL '6 hours',
    if_not_exists => TRUE
);
```

---

### NIVEL 3: DOWNSAMPLING JERÃRQUICO (PRÃ“XIMA SEMANA)

#### Estrategia de AgregaciÃ³n Multi-Nivel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIRÃMIDE DE DATOS                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚    NIVEL 4: Mensuales (retenciÃ³n: INDEFINIDA)                       â”‚
â”‚    â””â”€â”€ 1 fila por invernadero por mes                               â”‚
â”‚        â””â”€â”€ Agregados: avg, min, max, stddev                         â”‚
â”‚                                                                     â”‚
â”‚    NIVEL 3: Diarios (retenciÃ³n: 2 AÃ‘OS)                             â”‚
â”‚    â””â”€â”€ 1 fila por invernadero por dÃ­a                               â”‚
â”‚        â””â”€â”€ Agregados: avg, min, max, stddev, percentiles            â”‚
â”‚                                                                     â”‚
â”‚    NIVEL 2: Horarios (retenciÃ³n: 90 DÃAS)                           â”‚
â”‚    â””â”€â”€ 1 fila por invernadero por hora                              â”‚
â”‚        â””â”€â”€ Agregados: avg, min, max, count                          â”‚
â”‚                                                                     â”‚
â”‚    NIVEL 1: Datos crudos (retenciÃ³n: 7 DÃAS)                        â”‚
â”‚    â””â”€â”€ 1 fila por mensaje (~1/minuto)                               â”‚
â”‚        â””â”€â”€ Datos completos sin agregar                              â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ImplementaciÃ³n SQL

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- CONTINUOUS AGGREGATE NIVEL 2: HORARIO
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CREATE MATERIALIZED VIEW iot.greenhouse_hourly
WITH (timescaledb.continuous) AS
SELECT 
    time_bucket('1 hour', time) AS bucket,
    greenhouse_id,
    tenant_id,
    
    -- Temperatura promedio, min, max
    AVG(temp_invernadero_01) AS avg_temp_01,
    MIN(temp_invernadero_01) AS min_temp_01,
    MAX(temp_invernadero_01) AS max_temp_01,
    AVG(temp_invernadero_02) AS avg_temp_02,
    MIN(temp_invernadero_02) AS min_temp_02,
    MAX(temp_invernadero_02) AS max_temp_02,
    AVG(temp_invernadero_03) AS avg_temp_03,
    MIN(temp_invernadero_03) AS min_temp_03,
    MAX(temp_invernadero_03) AS max_temp_03,
    
    -- Humedad promedio
    AVG(hum_invernadero_01) AS avg_hum_01,
    MIN(hum_invernadero_01) AS min_hum_01,
    MAX(hum_invernadero_01) AS max_hum_01,
    AVG(hum_invernadero_02) AS avg_hum_02,
    AVG(hum_invernadero_03) AS avg_hum_03,
    
    -- Conteo de lecturas
    COUNT(*) AS reading_count
FROM iot.greenhouse_readings
GROUP BY bucket, greenhouse_id, tenant_id
WITH NO DATA;

-- PolÃ­tica de refresh (cada 15 minutos, datos de Ãºltima semana)
SELECT add_continuous_aggregate_policy('iot.greenhouse_hourly',
    start_offset => INTERVAL '7 days',
    end_offset => INTERVAL '1 hour',
    schedule_interval => INTERVAL '15 minutes',
    if_not_exists => TRUE
);

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- CONTINUOUS AGGREGATE NIVEL 3: DIARIO (sobre horario)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CREATE MATERIALIZED VIEW iot.greenhouse_daily
WITH (timescaledb.continuous) AS
SELECT 
    time_bucket('1 day', bucket) AS bucket,
    greenhouse_id,
    tenant_id,
    
    -- Agregados del dÃ­a
    AVG(avg_temp_01) AS avg_temp_01,
    MIN(min_temp_01) AS min_temp_01,
    MAX(max_temp_01) AS max_temp_01,
    AVG(avg_temp_02) AS avg_temp_02,
    AVG(avg_temp_03) AS avg_temp_03,
    
    AVG(avg_hum_01) AS avg_hum_01,
    MIN(min_hum_01) AS min_hum_01,
    MAX(max_hum_01) AS max_hum_01,
    
    SUM(reading_count) AS total_readings
FROM iot.greenhouse_hourly
GROUP BY bucket, greenhouse_id, tenant_id
WITH NO DATA;

-- Refresh cada 6 horas
SELECT add_continuous_aggregate_policy('iot.greenhouse_daily',
    start_offset => INTERVAL '30 days',
    end_offset => INTERVAL '6 hours',
    schedule_interval => INTERVAL '6 hours',
    if_not_exists => TRUE
);

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- CONTINUOUS AGGREGATE NIVEL 4: MENSUAL (sobre diario)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CREATE MATERIALIZED VIEW iot.greenhouse_monthly
WITH (timescaledb.continuous) AS
SELECT 
    time_bucket('1 month', bucket) AS bucket,
    greenhouse_id,
    tenant_id,
    
    AVG(avg_temp_01) AS avg_temp_01,
    MIN(min_temp_01) AS min_temp_01,
    MAX(max_temp_01) AS max_temp_01,
    AVG(avg_temp_02) AS avg_temp_02,
    AVG(avg_temp_03) AS avg_temp_03,
    
    AVG(avg_hum_01) AS avg_hum_01,
    
    SUM(total_readings) AS total_readings
FROM iot.greenhouse_daily
GROUP BY bucket, greenhouse_id, tenant_id
WITH NO DATA;

-- Refresh diario
SELECT add_continuous_aggregate_policy('iot.greenhouse_monthly',
    start_offset => INTERVAL '2 years',
    end_offset => INTERVAL '1 day',
    schedule_interval => INTERVAL '1 day',
    if_not_exists => TRUE
);
```

---

### NIVEL 4: POLÃTICAS DE RETENCIÃ“N AGRESIVAS

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- POLÃTICAS DE RETENCIÃ“N POR NIVEL
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- NIVEL 1: Datos crudos â†’ ELIMINAR DESPUÃ‰S DE 7 DÃAS
-- (Los datos ya estÃ¡n agregados en hourly)
SELECT add_retention_policy('iot.greenhouse_readings',
    drop_after => INTERVAL '7 days',
    if_not_exists => TRUE
);

-- NIVEL 2: Agregados horarios â†’ ELIMINAR DESPUÃ‰S DE 90 DÃAS
-- (Los datos ya estÃ¡n en daily)
SELECT add_retention_policy('iot.greenhouse_hourly',
    drop_after => INTERVAL '90 days',
    if_not_exists => TRUE
);

-- NIVEL 3: Agregados diarios â†’ ELIMINAR DESPUÃ‰S DE 2 AÃ‘OS
-- (Los datos ya estÃ¡n en monthly)
SELECT add_retention_policy('iot.greenhouse_daily',
    drop_after => INTERVAL '2 years',
    if_not_exists => TRUE
);

-- NIVEL 4: Agregados mensuales â†’ RETENCIÃ“N INDEFINIDA
-- (Mantener para histÃ³rico y cumplimiento)
-- No se agrega polÃ­tica de retenciÃ³n
```

---

## ğŸ“ˆ PROYECCIÃ“N DE ALMACENAMIENTO

### Escenario Actual (sin optimizar)
```
Frecuencia:       1 mensaje cada ~0.8 segundos (~75/min)
Filas/dÃ­a:        ~2,400,000 (25 filas Ã— 96,000 mensajes)
TamaÃ±o/dÃ­a:       ~400 MB sin comprimir, ~40 MB comprimido
TamaÃ±o/mes:       ~1.2 GB comprimido
TamaÃ±o/aÃ±o:       ~14.4 GB comprimido

âš ï¸ Con disco de 12 GB, se llenarÃ­a en ~8 meses
```

### Escenario Optimizado (con estrategia completa)
```
Frecuencia:       1 mensaje cada 60 segundos (12/min)
Modelo:           1 fila por mensaje (no 25)
Filas/dÃ­a:        ~17,280 (1 fila Ã— 17,280 mensajes)
RetenciÃ³n:        7 dÃ­as raw â†’ 90 dÃ­as hourly â†’ 2 aÃ±os daily

TamaÃ±o estimado:
  - Raw (7 dÃ­as):     ~10 MB
  - Hourly (90 dÃ­as): ~30 MB
  - Daily (2 aÃ±os):   ~5 MB
  - Monthly (indef):  ~1 MB
  
TOTAL: ~50 MB vs ~1.2 GB actual

âœ… ReducciÃ³n del 96% en almacenamiento
```

---

## ğŸš€ PLAN DE IMPLEMENTACIÃ“N

### Fase 1: Emergencia (HOY - 30 minutos)

```bash
# 1. Detener datos duplicados
kubectl scale deployment/invernaderos-api -n apptolast-invernadero-api-prod --replicas=1

# 2. Verificar
kubectl get pods -n apptolast-invernadero-api-prod
# Debe mostrar solo 1 pod Running
```

### Fase 2: ConfiguraciÃ³n (HOY - 1 hora)

```bash
# 1. Actualizar intervalo de simulaciÃ³n a 60 segundos
# Editar el configmap
kubectl edit configmap invernaderos-api-config -n apptolast-invernadero-api-prod

# Cambiar:
#   interval-ms: 5000
# Por:
#   interval-ms: 60000

# 2. Reiniciar el deployment
kubectl rollout restart deployment/invernaderos-api -n apptolast-invernadero-api-prod
```

### Fase 3: MigraciÃ³n de Esquema (Esta semana)

1. Crear la nueva tabla `greenhouse_readings`
2. Modificar `MqttMessageProcessor` para escribir en el nuevo formato
3. Crear continuous aggregates
4. Configurar polÃ­ticas de retenciÃ³n
5. Migrar datos histÃ³ricos (opcional)

### Fase 4: ValidaciÃ³n (PrÃ³xima semana)

1. Monitorear tamaÃ±o de base de datos
2. Verificar que las agregaciones funcionan
3. Confirmar que los dashboards/apps siguen funcionando
4. Ajustar polÃ­ticas segÃºn sea necesario

---

## ğŸ”§ SCRIPT DE IMPLEMENTACIÃ“N RÃPIDA

```bash
#!/bin/bash
# emergency-fix.sh - Ejecutar AHORA

echo "ğŸš¨ EMERGENCIA: Reduciendo duplicaciÃ³n de datos..."

# 1. Reducir a 1 rÃ©plica en producciÃ³n
kubectl scale deployment/invernaderos-api -n apptolast-invernadero-api-prod --replicas=1

# 2. Desactivar simulaciÃ³n en desarrollo
kubectl set env deployment/invernaderos-api -n apptolast-invernadero-api-dev \
  GREENHOUSE_SIMULATION_ENABLED=false

# 3. Verificar
echo "âœ… Verificando cambios..."
kubectl get pods -n apptolast-invernadero-api-prod
kubectl get pods -n apptolast-invernadero-api-dev

echo ""
echo "â³ Esperar 5 minutos y verificar frecuencia de datos..."
echo "   PGPASSWORD='...' psql -h 138.199.157.58 -p 30432 -U admin -d greenhouse_timeseries -c \\"
echo "   \"SELECT COUNT(*) / 5.0 as msgs_per_minute FROM iot.sensor_readings WHERE time >= NOW() - INTERVAL '5 minutes';\""
```

---

## ğŸ“‹ CHECKLIST DE VALIDACIÃ“N

- [ ] Solo 1 rÃ©plica en producciÃ³n
- [ ] SimulaciÃ³n desactivada en desarrollo
- [ ] Frecuencia de mensajes ~12/minuto (no ~75/minuto)
- [ ] Intervalo de simulaciÃ³n = 60 segundos
- [ ] CompresiÃ³n funcionando (chunks comprimidos)
- [ ] PolÃ­ticas de retenciÃ³n configuradas
- [ ] Alertas de disco configuradas (70%, 85%)

---

## â“ DECISIONES PENDIENTES

1. **Â¿Mantener simulaciÃ³n o usar datos reales?**
   - Si hay sensores reales: desactivar simulaciÃ³n completamente
   - Si no hay sensores: mantener simulaciÃ³n con intervalo de 60 seg

2. **Â¿RetenciÃ³n de datos crudos?**
   - 7 dÃ­as (recomendado para ahorro mÃ¡ximo)
   - 30 dÃ­as (si necesitas debugging)
   - 90 dÃ­as (mÃ¡ximo razonable)

3. **Â¿Migrar a modelo columnar?**
   - SÃ­: Requiere cambios en la API
   - No: Mantener modelo actual con mejor configuraciÃ³n

---

## ğŸ“ CONTACTO

Si tienes dudas sobre la implementaciÃ³n, discutamos:
- Prioridad de los cambios
- Impacto en la aplicaciÃ³n mÃ³vil
- Necesidades de retenciÃ³n de datos
- Frecuencia Ã³ptima de muestreo

**Â¡ESTO ES CRÃTICO - ACTUAR HOY!**
